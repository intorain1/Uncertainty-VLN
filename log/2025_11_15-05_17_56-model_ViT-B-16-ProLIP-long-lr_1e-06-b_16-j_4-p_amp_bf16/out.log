2025-11-15,05:17:56 | INFO | Running with a single process. Device cuda:0.
2025-11-15,05:17:56 | INFO | Loaded ViT-B-16-ProLIP-long model config.
2025-11-15,05:17:58 | INFO | Model:
2025-11-15,05:17:58 | INFO | ProLIP(
  (visual): VisionTransformer(
    (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (transformer): Transformer(
      (resblocks): ModuleList(
        (0-11): 12 x ResidualAttentionBlock(
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ls_1): Identity()
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): GELU(approximate='none')
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ls_2): Identity()
        )
      )
    )
    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (uncertainty_proj): Linear(in_features=768, out_features=768, bias=True)
  )
  (text): TextTransformer(
    (token_embedding): Embedding(32100, 768)
    (transformer): Transformer(
      (resblocks): ModuleList(
        (0-11): 12 x ResidualAttentionBlock(
          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ls_1): Identity()
          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): GELU(approximate='none')
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ls_2): Identity()
        )
      )
    )
    (ln_final): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (text_projection): Linear(in_features=768, out_features=768, bias=True)
    (text_uncertainty_projection): Linear(in_features=768, out_features=768, bias=True)
  )
  (ts_mean): TSTransformer(
    (input_proj): Identity()
    (transformer): Transformer(
      (resblocks): ModuleList(
        (0-3): 4 x ResidualAttentionBlock(
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ls_1): Identity()
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ls_2): Identity()
        )
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (ts_std): TSTransformer(
    (input_proj): Identity()
    (transformer): Transformer(
      (resblocks): ModuleList(
        (0-3): 4 x ResidualAttentionBlock(
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ls_1): Identity()
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ls_2): Identity()
        )
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
)
2025-11-15,05:17:58 | INFO | Params:
2025-11-15,05:17:58 | INFO |   accum_freq: 1
2025-11-15,05:17:58 | INFO |   adamp: False
2025-11-15,05:17:58 | INFO |   aug_cfg: {'scale': (0.8, 1.0), 'color_jitter': (0.32, 0.32, 0.32, 0.08), 'color_jitter_prob': 0.8, 'gray_scale_prob': 0.2}
2025-11-15,05:17:58 | INFO |   batch_size: 16
2025-11-15,05:17:58 | INFO |   beta1: 0.9
2025-11-15,05:17:58 | INFO |   beta2: 0.95
2025-11-15,05:17:58 | INFO |   checkpoint_path: /home/user/intorains/Uncertainty-VLN/log/2025_11_15-05_17_56-model_ViT-B-16-ProLIP-long-lr_1e-06-b_16-j_4-p_amp_bf16/checkpoints
2025-11-15,05:17:58 | INFO |   coca_caption_loss_weight: 2.0
2025-11-15,05:17:58 | INFO |   coca_contrastive_loss_weight: 1.0
2025-11-15,05:17:58 | INFO |   coco_test: None
2025-11-15,05:17:58 | INFO |   copy_codebase: False
2025-11-15,05:17:58 | INFO |   csv_caption_key: title
2025-11-15,05:17:58 | INFO |   csv_img_key: filepath
2025-11-15,05:17:58 | INFO |   csv_separator: 	
2025-11-15,05:17:58 | INFO |   dataset_resampled: True
2025-11-15,05:17:58 | INFO |   dataset_type: seq
2025-11-15,05:17:58 | INFO |   ddp_static_graph: False
2025-11-15,05:17:58 | INFO |   debug: False
2025-11-15,05:17:58 | INFO |   delete_previous_checkpoint: True
2025-11-15,05:17:58 | INFO |   device: cuda:0
2025-11-15,05:17:58 | INFO |   dist_backend: nccl
2025-11-15,05:17:58 | INFO |   dist_url: env://
2025-11-15,05:17:58 | INFO |   distill: False
2025-11-15,05:17:58 | INFO |   distill_model: None
2025-11-15,05:17:58 | INFO |   distill_pretrained: None
2025-11-15,05:17:58 | INFO |   distributed: False
2025-11-15,05:17:58 | INFO |   drop_prob: 0.75
2025-11-15,05:17:58 | INFO |   drop_ratio: 0.125
2025-11-15,05:17:58 | INFO |   epochs: 32
2025-11-15,05:17:58 | INFO |   epochs_cooldown: None
2025-11-15,05:17:58 | INFO |   eps: 1e-06
2025-11-15,05:17:58 | INFO |   force_custom_text: False
2025-11-15,05:17:58 | INFO |   force_image_size: None
2025-11-15,05:17:58 | INFO |   force_patch_dropout: None
2025-11-15,05:17:58 | INFO |   force_quick_gelu: False
2025-11-15,05:17:58 | INFO |   force_resize_n_cls: 2
2025-11-15,05:17:58 | INFO |   force_resize_pos_emb: True
2025-11-15,05:17:58 | INFO |   gather_with_grad: False
2025-11-15,05:17:58 | INFO |   grad_checkpointing: False
2025-11-15,05:17:58 | INFO |   grad_clip_norm: None
2025-11-15,05:17:58 | INFO |   horovod: False
2025-11-15,05:17:58 | INFO |   image_interpolation: None
2025-11-15,05:17:58 | INFO |   image_mean: None
2025-11-15,05:17:58 | INFO |   image_resize_mode: None
2025-11-15,05:17:58 | INFO |   image_std: None
2025-11-15,05:17:58 | INFO |   imagenet_v2: None
2025-11-15,05:17:58 | INFO |   imagenet_val: None
2025-11-15,05:17:58 | INFO |   inclusion_alpha: 1e-07
2025-11-15,05:17:58 | INFO |   inclusion_alpha_occ: 0.001
2025-11-15,05:17:58 | INFO |   inclusion_eps: -100.0
2025-11-15,05:17:58 | INFO |   inclusion_scale: 10.0
2025-11-15,05:17:58 | INFO |   local_loss: False
2025-11-15,05:17:58 | INFO |   local_rank: 0
2025-11-15,05:17:58 | INFO |   lock_image: False
2025-11-15,05:17:58 | INFO |   lock_image_freeze_bn_stats: False
2025-11-15,05:17:58 | INFO |   lock_image_unlocked_groups: 0
2025-11-15,05:17:58 | INFO |   lock_text: False
2025-11-15,05:17:58 | INFO |   lock_text_freeze_layer_norm: False
2025-11-15,05:17:58 | INFO |   lock_text_unlocked_layers: 0
2025-11-15,05:17:58 | INFO |   log_every_n_steps: 100
2025-11-15,05:17:58 | INFO |   log_level: 20
2025-11-15,05:17:58 | INFO |   log_local: False
2025-11-15,05:17:58 | INFO |   log_path: /home/user/intorains/Uncertainty-VLN/log/2025_11_15-05_17_56-model_ViT-B-16-ProLIP-long-lr_1e-06-b_16-j_4-p_amp_bf16/out.log
2025-11-15,05:17:58 | INFO |   logs: /home/user/intorains/Uncertainty-VLN/log
2025-11-15,05:17:58 | INFO |   lr: 1e-06
2025-11-15,05:17:58 | INFO |   lr_cooldown_end: 0.0
2025-11-15,05:17:58 | INFO |   lr_cooldown_power: 1.0
2025-11-15,05:17:58 | INFO |   lr_scheduler: cosine
2025-11-15,05:17:58 | INFO |   model: ViT-B-16-ProLIP-long
2025-11-15,05:17:58 | INFO |   name: 2025_11_15-05_17_56-model_ViT-B-16-ProLIP-long-lr_1e-06-b_16-j_4-p_amp_bf16
2025-11-15,05:17:58 | INFO |   no_set_device_rank: False
2025-11-15,05:17:58 | INFO |   ppcl_lambda: 1.0
2025-11-15,05:17:58 | INFO |   precision: amp_bf16
2025-11-15,05:17:58 | INFO |   pretrained: 
2025-11-15,05:17:58 | INFO |   pretrained_image: False
2025-11-15,05:17:58 | INFO |   prolip: True
2025-11-15,05:17:58 | INFO |   prolip_logs: /home/user/intorains/Uncertainty-VLN/log
2025-11-15,05:17:58 | INFO |   rank: 0
2025-11-15,05:17:58 | INFO |   reinit_unc: False
2025-11-15,05:17:58 | INFO |   remote_sync: None
2025-11-15,05:17:58 | INFO |   remote_sync_frequency: 300
2025-11-15,05:17:58 | INFO |   remote_sync_protocol: s3
2025-11-15,05:17:58 | INFO |   replace_token: 32000
2025-11-15,05:17:58 | INFO |   report_to: 
2025-11-15,05:17:58 | INFO |   resume: None
2025-11-15,05:17:58 | INFO |   save_best_unc: False
2025-11-15,05:17:58 | INFO |   save_frequency: 1
2025-11-15,05:17:58 | INFO |   save_most_recent: False
2025-11-15,05:17:58 | INFO |   seed: 0
2025-11-15,05:17:58 | INFO |   siglip: False
2025-11-15,05:17:58 | INFO |   siglip_lambda: 0
2025-11-15,05:17:58 | INFO |   skip_scheduler: False
2025-11-15,05:17:58 | INFO |   tensorboard: False
2025-11-15,05:17:58 | INFO |   tensorboard_path: 
2025-11-15,05:17:58 | INFO |   torchcompile: False
2025-11-15,05:17:58 | INFO |   torchscript: False
2025-11-15,05:17:58 | INFO |   trace: False
2025-11-15,05:17:58 | INFO |   train_data: /home/user/intorains/Matterport3D_O
2025-11-15,05:17:58 | INFO |   train_data_upsampling_factors: None
2025-11-15,05:17:58 | INFO |   train_num_samples: 8000000
2025-11-15,05:17:58 | INFO |   use_bn_sync: False
2025-11-15,05:17:58 | INFO |   use_bnb_linear: None
2025-11-15,05:17:58 | INFO |   val_data: None
2025-11-15,05:17:58 | INFO |   val_frequency: 1
2025-11-15,05:17:58 | INFO |   val_num_samples: None
2025-11-15,05:17:58 | INFO |   vib_beta: 0.0001
2025-11-15,05:17:58 | INFO |   wandb: False
2025-11-15,05:17:58 | INFO |   wandb_notes: 
2025-11-15,05:17:58 | INFO |   wandb_project_name: open-clip
2025-11-15,05:17:58 | INFO |   warmup: 200
2025-11-15,05:17:58 | INFO |   wd: 0.01
2025-11-15,05:17:58 | INFO |   workers: 4
2025-11-15,05:17:58 | INFO |   world_size: 1
2025-11-15,05:17:58 | INFO |   zeroshot_frequency: 1
2025-11-15,05:18:07 | WARNING | '(MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /timm/ViT-B-16-SigLIP/resolve/main/tokenizer_config.json (Caused by SSLError(SSLZeroReturnError(6, 'TLS/SSL connection has been closed (EOF) (_ssl.c:1147)')))"), '(Request ID: 64367399-2c8c-49bc-8ed4-396cefb0a370)')' thrown while requesting HEAD https://huggingface.co/timm/ViT-B-16-SigLIP/resolve/main/tokenizer_config.json
2025-11-15,05:18:07 | WARNING | Retrying in 1s [Retry 1/5].
2025-11-15,05:18:10 | WARNING | '(MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /timm/ViT-B-16-SigLIP/resolve/main/tokenizer_config.json (Caused by SSLError(SSLZeroReturnError(6, 'TLS/SSL connection has been closed (EOF) (_ssl.c:1147)')))"), '(Request ID: afa8e7e4-ecd6-481b-ab44-b2b0c7ff09f5)')' thrown while requesting HEAD https://huggingface.co/timm/ViT-B-16-SigLIP/resolve/main/tokenizer_config.json
2025-11-15,05:18:10 | WARNING | Retrying in 2s [Retry 2/5].
2025-11-15,05:18:20 | WARNING | '(MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /timm/ViT-B-16-SigLIP/resolve/main/tokenizer_config.json (Caused by SSLError(SSLZeroReturnError(6, 'TLS/SSL connection has been closed (EOF) (_ssl.c:1147)')))"), '(Request ID: dc0894e3-ba85-4534-a6be-1038ace1fcb8)')' thrown while requesting HEAD https://huggingface.co/timm/ViT-B-16-SigLIP/resolve/main/tokenizer_config.json
2025-11-15,05:18:20 | WARNING | Retrying in 4s [Retry 3/5].
